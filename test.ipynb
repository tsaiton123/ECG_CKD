{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 15:07:27.629396: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-29 15:07:27.668944: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-29 15:07:27.668985: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-29 15:07:27.669023: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-29 15:07:27.676496: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-29 15:07:28.714815: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.1) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "2024-08-29 15:07:29.965036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13581 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:ca:00.0, compute capability: 7.5\n",
      "2024-08-29 15:07:40.223327: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.00GiB (rounded to 4294967296)requested by op AddV2\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2024-08-29 15:07:40.223395: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2024-08-29 15:07:40.223423: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 15, Chunks in use: 15. 3.8KiB allocated for chunks. 3.8KiB in use in bin. 388B client-requested in use in bin.\n",
      "2024-08-29 15:07:40.223441: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-29 15:07:40.223458: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 2, Chunks in use: 2. 2.2KiB allocated for chunks. 2.2KiB in use in bin. 2.0KiB client-requested in use in bin.\n",
      "2024-08-29 15:07:40.223472: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-29 15:07:40.223489: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 2, Chunks in use: 2. 9.5KiB allocated for chunks. 9.5KiB in use in bin. 8.0KiB client-requested in use in bin.\n",
      "2024-08-29 15:07:40.223502: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-29 15:07:40.223516: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-29 15:07:40.223529: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-29 15:07:40.223543: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-29 15:07:40.223556: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-29 15:07:40.223569: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-29 15:07:40.223583: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-29 15:07:40.223599: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 2, Chunks in use: 1. 3.00MiB allocated for chunks. 1.00MiB in use in bin. 1.00MiB client-requested in use in bin.\n",
      "2024-08-29 15:07:40.223612: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-29 15:07:40.223626: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-29 15:07:40.223639: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-29 15:07:40.223653: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-29 15:07:40.223666: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-29 15:07:40.223685: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 1, Chunks in use: 1. 64.00MiB allocated for chunks. 64.00MiB in use in bin. 64.00MiB client-requested in use in bin.\n",
      "2024-08-29 15:07:40.223700: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 1, Chunks in use: 0. 128.00MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-29 15:07:40.223723: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 5, Chunks in use: 3. 13.07GiB allocated for chunks. 9.00GiB in use in bin. 9.00GiB client-requested in use in bin.\n",
      "2024-08-29 15:07:40.223739: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 4.00GiB was 256.00MiB, Chunk State: \n",
      "2024-08-29 15:07:40.223767: I tensorflow/tsl/framework/bfc_allocator.cc:1068]   Size: 2.00GiB | Requested Size: 1.00GiB | in_use: 0 | bin_num: 20, prev:   Size: 64.00MiB | Requested Size: 64.00MiB | in_use: 1 | bin_num: -1, next:   Size: 1.00GiB | Requested Size: 1.00GiB | in_use: 1 | bin_num: -1\n",
      "2024-08-29 15:07:40.223785: I tensorflow/tsl/framework/bfc_allocator.cc:1068]   Size: 2.07GiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 4.00GiB | Requested Size: 4.00GiB | in_use: 1 | bin_num: -1\n",
      "2024-08-29 15:07:40.223797: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 14241562624\n",
      "2024-08-29 15:07:40.223811: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 759d2e000000 of size 1280 next 1\n",
      "2024-08-29 15:07:40.223824: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 759d2e000500 of size 256 next 2\n",
      "2024-08-29 15:07:40.223835: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 759d2e000600 of size 256 next 3\n",
      "2024-08-29 15:07:40.223846: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 759d2e000700 of size 256 next 5\n",
      "2024-08-29 15:07:40.223857: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 759d2e000800 of size 256 next 6\n",
      "2024-08-29 15:07:40.223868: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 759d2e000900 of size 256 next 4\n",
      "2024-08-29 15:07:40.223879: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 759d2e000a00 of size 256 next 7\n",
      "2024-08-29 15:07:40.223891: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 759d2e000b00 of size 256 next 12\n",
      "2024-08-29 15:07:40.223901: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 759d2e000c00 of size 256 next 10\n",
      "2024-08-29 15:07:40.223913: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 759d2e000d00 of size 256 next 11\n",
      "2024-08-29 15:07:40.223925: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 759d2e000e00 of size 1024 next 17\n",
      "2024-08-29 15:07:40.223937: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 759d2e001200 of size 256 next 15\n",
      "2024-08-29 15:07:40.223948: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 759d2e001300 of size 256 next 16\n",
      "2024-08-29 15:07:40.223960: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 759d2e001400 of size 5632 next 8\n",
      "2024-08-29 15:07:40.223972: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 759d2e002a00 of size 4096 next 9\n",
      "2024-08-29 15:07:40.223983: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 759d2e003a00 of size 256 next 22\n",
      "2024-08-29 15:07:40.223994: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 759d2e003b00 of size 256 next 20\n",
      "2024-08-29 15:07:40.224005: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 759d2e003c00 of size 256 next 21\n",
      "2024-08-29 15:07:40.224016: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 759d2e003d00 of size 256 next 25\n",
      "2024-08-29 15:07:40.224027: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 759d2e003e00 of size 2096128 next 14\n",
      "2024-08-29 15:07:40.224039: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 759d2e203a00 of size 1048576 next 13\n",
      "2024-08-29 15:07:40.224051: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 759d2e303a00 of size 134217728 next 19\n",
      "2024-08-29 15:07:40.224063: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 759d36303a00 of size 67108864 next 18\n",
      "2024-08-29 15:07:40.224074: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 759d3a303a00 of size 2147483648 next 24\n",
      "2024-08-29 15:07:40.224085: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 759dba303a00 of size 1073741824 next 23\n",
      "2024-08-29 15:07:40.224098: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 759dfa303a00 of size 4294967296 next 26\n",
      "2024-08-29 15:07:40.224110: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 759efa303a00 of size 4294967296 next 28\n",
      "2024-08-29 15:07:40.224122: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 759ffa303a00 of size 2225915392 next 18446744073709551615\n",
      "2024-08-29 15:07:40.224133: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2024-08-29 15:07:40.224148: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 15 Chunks of size 256 totalling 3.8KiB\n",
      "2024-08-29 15:07:40.224161: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1024 totalling 1.0KiB\n",
      "2024-08-29 15:07:40.224173: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2024-08-29 15:07:40.224186: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 4096 totalling 4.0KiB\n",
      "2024-08-29 15:07:40.224198: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 5632 totalling 5.5KiB\n",
      "2024-08-29 15:07:40.224210: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1048576 totalling 1.00MiB\n",
      "2024-08-29 15:07:40.224223: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 67108864 totalling 64.00MiB\n",
      "2024-08-29 15:07:40.224236: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1073741824 totalling 1.00GiB\n",
      "2024-08-29 15:07:40.224248: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 4294967296 totalling 8.00GiB\n",
      "2024-08-29 15:07:40.224261: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 9.06GiB\n",
      "2024-08-29 15:07:40.224273: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 14241562624 memory_limit_: 14241562624 available bytes: 0 curr_region_allocation_bytes_: 28483125248\n",
      "2024-08-29 15:07:40.224294: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                     14241562624\n",
      "InUse:                      9731849728\n",
      "MaxInUse:                   9731849984\n",
      "NumAllocs:                          45\n",
      "MaxAllocSize:               4294967296\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2024-08-29 15:07:40.224311: W tensorflow/tsl/framework/bfc_allocator.cc:497] **______________*********************************************************************_______________\n",
      "2024-08-29 15:07:40.224335: W tensorflow/core/framework/op_kernel.cc:1827] RESOURCE_EXHAUSTED: failed to allocate memory\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:AddV2] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m5000\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# ECG input shape\u001b[39;00m\n\u001b[1;32m     39\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m71\u001b[39m  \u001b[38;5;66;03m# Number of output classes\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_ecg_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Model summary\u001b[39;00m\n\u001b[1;32m     43\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m, in \u001b[0;36mbuild_ecg_model\u001b[0;34m(input_shape, num_classes)\u001b[0m\n\u001b[1;32m     10\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mConv2D(filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1024\u001b[39m), strides\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m8\u001b[39m), padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[1;32m     11\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mConv2D(filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1024\u001b[39m), strides\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m8\u001b[39m), padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[0;32m---> 12\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Spatial Convolution\u001b[39;00m\n\u001b[1;32m     15\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mConv2D(filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m1\u001b[39m), padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:2102\u001b[0m, in \u001b[0;36mRandomGenerator.random_uniform\u001b[0;34m(self, shape, minval, maxval, dtype, nonce)\u001b[0m\n\u001b[1;32m   2100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonce:\n\u001b[1;32m   2101\u001b[0m         seed \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mstateless_fold_in(seed, nonce)\n\u001b[0;32m-> 2102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstateless_uniform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mminval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mminval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaxval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\n\u001b[1;32m   2110\u001b[0m     shape\u001b[38;5;241m=\u001b[39mshape,\n\u001b[1;32m   2111\u001b[0m     minval\u001b[38;5;241m=\u001b[39mminval,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2114\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_legacy_seed(),\n\u001b[1;32m   2115\u001b[0m )\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:AddV2] name: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_ecg_model(input_shape=(12, 5000, 1), num_classes=71):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    # Temporal Convolution\n",
    "    x = layers.Conv2D(filters=16, kernel_size=(1, 64), strides=(1, 8), padding='same', activation='relu')(inputs)\n",
    "    x = layers.Conv2D(filters=64, kernel_size=(1, 256), strides=(1, 8), padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(filters=256, kernel_size=(1, 1024), strides=(1, 8), padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(filters=1024, kernel_size=(1, 1024), strides=(1, 8), padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(filters=1024, kernel_size=(1, 1024), strides=(1, 8), padding='same', activation='relu')(x)\n",
    "\n",
    "    # Spatial Convolution\n",
    "    x = layers.Conv2D(filters=4, kernel_size=(5, 1), padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=(5, 1), padding='same', activation='relu')(x)\n",
    "    \n",
    "    # Feature Convolutions\n",
    "    x = layers.SeparableConv2D(filters=16, kernel_size=(1, 16), depth_multiplier=1, strides=(1, 4), padding='same', activation='relu')(x)\n",
    "    x = layers.SeparableConv2D(filters=32, kernel_size=(1, 16), depth_multiplier=2, strides=(1, 2), padding='same', activation='relu')(x)\n",
    "    \n",
    "    # Flatten and Bi-LSTM\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(64, return_sequences=False))(x)\n",
    "    \n",
    "    # Batch Normalization\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    # Dense Output\n",
    "    outputs = layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "    # Create the model\n",
    "    model = models.Model(inputs, outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Model creation\n",
    "input_shape = (12, 5000, 1)  # ECG input shape\n",
    "num_classes = 71  # Number of output classes\n",
    "model = build_ecg_model(input_shape, num_classes)\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
